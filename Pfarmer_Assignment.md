---
geometry: margin=30mm
title: "Machine Learning Final Assignment"
author: "Student Name: Patrick Farmer       Student Number: 20331828"
date: "Date: 30-11-2024"
---

# Part 1

### Introduction

Sequential pitch, timing, combined and resultant vocubulary adjustment
Cosine similarity loss
Added temperature for creativity
Reduced block size from text generation as context is more localised
Larger batch sizes to encourage faster convergence
Convergence mux faster so heavily decreased iterations and evaluation intervals
Reduced dropout as rhytms are less complex
Sounded too similar to input so increased temperature and added noise to improve generalisation
Added pattern stretch and shrink to improve generalisation and torch cat all datasets together
Added 1D convolution layers before Transformer blocks to extract local rhythm patterns
Evaluation
Separation perhaps more useful if more complex rhythms

### Data Preprocessing and feature engineering

### Machine Learning methodology

### Evaluation

# Part 2

### What is an ROC curve? How can it be used to evaluate the performance of a classifier compared with a baseline classifier? Why would you use an ROC curve instead of a classification accuracy metric?

### Give two examples of situations where a linear regression would give inaccurate predictions. Explain your reasoning and what possible solutions you would adopt in each situation.

### The term 'kernel' has different meanings in SVM and CNN models. Explain the two different meanings. Discuss why and when the use of SVM kernels and CNN kernels is useful, as well as mentioning different types of kernels.

### In k-fold cross-validation, a dataset is resampled multiple times. What is the idea behind this resampling i.e. why does resampling allow us to evaluate the generalisation performance of a machine learning mode. Give a small example to illustrate. Discuss when it is and it is not appropriate to use k-fold cross-validation.
